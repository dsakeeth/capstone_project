{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135b709d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def create_folders_from_file(file_path, base_directory):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            for line in file:\n",
    "                folder_name = line.strip()  # Remove leading/trailing whitespace\n",
    "                folder_path = os.path.join(base_directory, folder_name)\n",
    "\n",
    "                if not os.path.exists(folder_path):\n",
    "                    os.makedirs(folder_path)\n",
    "                    print(f\"Created folder: {folder_path}\")\n",
    "                else:\n",
    "                    print(f\"Folder already exists: {folder_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    folder_names_file = \"new_classes.txt\"  # Replace with the path to your file containing folder names\n",
    "    base_directory = \"new_dataset\"  # Replace with the path to the base directory\n",
    "\n",
    "    create_folders_from_file(folder_names_file, base_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2127c4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Noodles https://www.allrecipes.com/search?Noodles=Noodles&offset=0&q=Noodles&page=1\n",
      "Noodles https://www.allrecipes.com/search?Noodles=Noodles&offset=12&q=Noodles&page=2\n",
      "Noodles https://www.allrecipes.com/search?Noodles=Noodles&offset=24&q=Noodles&page=3\n",
      "Noodles https://www.allrecipes.com/search?Noodles=Noodles&offset=36&q=Noodles&page=4\n",
      "Noodles https://www.allrecipes.com/search?Noodles=Noodles&offset=48&q=Noodles&page=5\n",
      "Noodles https://www.allrecipes.com/search?Noodles=Noodles&offset=60&q=Noodles&page=6\n",
      "Noodles https://www.allrecipes.com/search?Noodles=Noodles&offset=72&q=Noodles&page=7\n",
      "Noodles https://www.allrecipes.com/search?Noodles=Noodles&offset=84&q=Noodles&page=8\n",
      "Noodles https://www.allrecipes.com/search?Noodles=Noodles&offset=96&q=Noodles&page=9\n",
      "Noodles https://www.allrecipes.com/search?Noodles=Noodles&offset=108&q=Noodles&page=10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Fried https://www.allrecipes.com/search?Fried=Fried&offset=0&q=Fried&page=1\n",
      "Error while scraping: [WinError 3] The system cannot find the path specified: 'new_dataset\\\\Fried'\n",
      "Fried https://www.allrecipes.com/search?Fried=Fried&offset=12&q=Fried&page=2\n",
      "Error while scraping: [WinError 3] The system cannot find the path specified: 'new_dataset\\\\Fried'\n",
      "Fried https://www.allrecipes.com/search?Fried=Fried&offset=24&q=Fried&page=3\n",
      "Error while scraping: [WinError 3] The system cannot find the path specified: 'new_dataset\\\\Fried'\n",
      "Fried https://www.allrecipes.com/search?Fried=Fried&offset=36&q=Fried&page=4\n",
      "Error while scraping: [WinError 3] The system cannot find the path specified: 'new_dataset\\\\Fried'\n",
      "Fried https://www.allrecipes.com/search?Fried=Fried&offset=48&q=Fried&page=5\n",
      "Error while scraping: [WinError 3] The system cannot find the path specified: 'new_dataset\\\\Fried'\n",
      "Fried https://www.allrecipes.com/search?Fried=Fried&offset=60&q=Fried&page=6\n",
      "Error while scraping: [WinError 3] The system cannot find the path specified: 'new_dataset\\\\Fried'\n",
      "Fried https://www.allrecipes.com/search?Fried=Fried&offset=72&q=Fried&page=7\n",
      "Error while scraping: [WinError 3] The system cannot find the path specified: 'new_dataset\\\\Fried'\n",
      "Fried https://www.allrecipes.com/search?Fried=Fried&offset=84&q=Fried&page=8\n",
      "Error while scraping: [WinError 3] The system cannot find the path specified: 'new_dataset\\\\Fried'\n",
      "Fried https://www.allrecipes.com/search?Fried=Fried&offset=96&q=Fried&page=9\n",
      "Error while scraping: [WinError 3] The system cannot find the path specified: 'new_dataset\\\\Fried'\n",
      "Fried https://www.allrecipes.com/search?Fried=Fried&offset=108&q=Fried&page=10\n",
      "Error while scraping: [WinError 3] The system cannot find the path specified: 'new_dataset\\\\Fried'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Rice https://www.allrecipes.com/search?Rice=Rice&offset=0&q=Rice&page=1\n",
      "Error while scraping: [WinError 3] The system cannot find the path specified: 'new_dataset\\\\Rice'\n",
      "Rice https://www.allrecipes.com/search?Rice=Rice&offset=12&q=Rice&page=2\n",
      "Error while scraping: [WinError 3] The system cannot find the path specified: 'new_dataset\\\\Rice'\n",
      "Rice https://www.allrecipes.com/search?Rice=Rice&offset=24&q=Rice&page=3\n",
      "Error while scraping: [WinError 3] The system cannot find the path specified: 'new_dataset\\\\Rice'\n",
      "Rice https://www.allrecipes.com/search?Rice=Rice&offset=36&q=Rice&page=4\n",
      "Error while scraping: [WinError 3] The system cannot find the path specified: 'new_dataset\\\\Rice'\n",
      "Rice https://www.allrecipes.com/search?Rice=Rice&offset=48&q=Rice&page=5\n",
      "Error while scraping: [WinError 3] The system cannot find the path specified: 'new_dataset\\\\Rice'\n",
      "Rice https://www.allrecipes.com/search?Rice=Rice&offset=60&q=Rice&page=6\n",
      "Error while scraping: [WinError 3] The system cannot find the path specified: 'new_dataset\\\\Rice'\n",
      "Rice https://www.allrecipes.com/search?Rice=Rice&offset=72&q=Rice&page=7\n",
      "Error while scraping: [WinError 3] The system cannot find the path specified: 'new_dataset\\\\Rice'\n",
      "Rice https://www.allrecipes.com/search?Rice=Rice&offset=84&q=Rice&page=8\n",
      "Error while scraping: [WinError 3] The system cannot find the path specified: 'new_dataset\\\\Rice'\n",
      "Rice https://www.allrecipes.com/search?Rice=Rice&offset=96&q=Rice&page=9\n",
      "Error while scraping: [WinError 3] The system cannot find the path specified: 'new_dataset\\\\Rice'\n",
      "Rice https://www.allrecipes.com/search?Rice=Rice&offset=108&q=Rice&page=10\n",
      "Error while scraping: [WinError 3] The system cannot find the path specified: 'new_dataset\\\\Rice'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Vegetable https://www.allrecipes.com/search?Vegetable=Vegetable&offset=0&q=Vegetable&page=1\n",
      "Error while scraping: [WinError 3] The system cannot find the path specified: 'new_dataset\\\\Vegetable'\n",
      "Vegetable https://www.allrecipes.com/search?Vegetable=Vegetable&offset=12&q=Vegetable&page=2\n",
      "Error while scraping: [WinError 3] The system cannot find the path specified: 'new_dataset\\\\Vegetable'\n",
      "Vegetable https://www.allrecipes.com/search?Vegetable=Vegetable&offset=24&q=Vegetable&page=3\n",
      "Error while scraping: [WinError 3] The system cannot find the path specified: 'new_dataset\\\\Vegetable'\n",
      "Vegetable https://www.allrecipes.com/search?Vegetable=Vegetable&offset=36&q=Vegetable&page=4\n",
      "Error while scraping: [WinError 3] The system cannot find the path specified: 'new_dataset\\\\Vegetable'\n",
      "Vegetable https://www.allrecipes.com/search?Vegetable=Vegetable&offset=48&q=Vegetable&page=5\n",
      "Error while scraping: [WinError 3] The system cannot find the path specified: 'new_dataset\\\\Vegetable'\n",
      "Vegetable https://www.allrecipes.com/search?Vegetable=Vegetable&offset=60&q=Vegetable&page=6\n",
      "Error while scraping: [WinError 3] The system cannot find the path specified: 'new_dataset\\\\Vegetable'\n",
      "Vegetable https://www.allrecipes.com/search?Vegetable=Vegetable&offset=72&q=Vegetable&page=7\n",
      "Error while scraping: [WinError 3] The system cannot find the path specified: 'new_dataset\\\\Vegetable'\n",
      "Vegetable https://www.allrecipes.com/search?Vegetable=Vegetable&offset=84&q=Vegetable&page=8\n",
      "Error while scraping: [WinError 3] The system cannot find the path specified: 'new_dataset\\\\Vegetable'\n",
      "Vegetable https://www.allrecipes.com/search?Vegetable=Vegetable&offset=96&q=Vegetable&page=9\n",
      "Error while scraping: [WinError 3] The system cannot find the path specified: 'new_dataset\\\\Vegetable'\n",
      "Vegetable https://www.allrecipes.com/search?Vegetable=Vegetable&offset=108&q=Vegetable&page=10\n",
      "Error while scraping: [WinError 3] The system cannot find the path specified: 'new_dataset\\\\Vegetable'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Soups https://www.allrecipes.com/search?Soups=Soups&offset=0&q=Soups&page=1\n",
      "Error while scraping: [WinError 3] The system cannot find the path specified: 'new_dataset\\\\Soups'\n",
      "Soups https://www.allrecipes.com/search?Soups=Soups&offset=12&q=Soups&page=2\n",
      "Error while scraping: [WinError 3] The system cannot find the path specified: 'new_dataset\\\\Soups'\n",
      "Soups https://www.allrecipes.com/search?Soups=Soups&offset=24&q=Soups&page=3\n",
      "Error while scraping: [WinError 3] The system cannot find the path specified: 'new_dataset\\\\Soups'\n",
      "Soups https://www.allrecipes.com/search?Soups=Soups&offset=36&q=Soups&page=4\n",
      "Error while scraping: [WinError 3] The system cannot find the path specified: 'new_dataset\\\\Soups'\n",
      "Soups https://www.allrecipes.com/search?Soups=Soups&offset=48&q=Soups&page=5\n",
      "Error while scraping: [WinError 3] The system cannot find the path specified: 'new_dataset\\\\Soups'\n",
      "Soups https://www.allrecipes.com/search?Soups=Soups&offset=60&q=Soups&page=6\n",
      "Error while scraping: [WinError 3] The system cannot find the path specified: 'new_dataset\\\\Soups'\n",
      "Soups https://www.allrecipes.com/search?Soups=Soups&offset=72&q=Soups&page=7\n",
      "Error while scraping: [WinError 3] The system cannot find the path specified: 'new_dataset\\\\Soups'\n",
      "Soups https://www.allrecipes.com/search?Soups=Soups&offset=84&q=Soups&page=8\n",
      "Error while scraping: [WinError 3] The system cannot find the path specified: 'new_dataset\\\\Soups'\n",
      "Soups https://www.allrecipes.com/search?Soups=Soups&offset=96&q=Soups&page=9\n",
      "Error while scraping: [WinError 3] The system cannot find the path specified: 'new_dataset\\\\Soups'\n",
      "Soups https://www.allrecipes.com/search?Soups=Soups&offset=108&q=Soups&page=10\n",
      "Error while scraping: [WinError 3] The system cannot find the path specified: 'new_dataset\\\\Soups'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Pasta https://www.allrecipes.com/search?Pasta=Pasta&offset=0&q=Pasta&page=1\n",
      "Pasta https://www.allrecipes.com/search?Pasta=Pasta&offset=12&q=Pasta&page=2\n",
      "Pasta https://www.allrecipes.com/search?Pasta=Pasta&offset=24&q=Pasta&page=3\n",
      "Pasta https://www.allrecipes.com/search?Pasta=Pasta&offset=36&q=Pasta&page=4\n",
      "Pasta https://www.allrecipes.com/search?Pasta=Pasta&offset=48&q=Pasta&page=5\n",
      "Pasta https://www.allrecipes.com/search?Pasta=Pasta&offset=60&q=Pasta&page=6\n",
      "Pasta https://www.allrecipes.com/search?Pasta=Pasta&offset=72&q=Pasta&page=7\n",
      "Pasta https://www.allrecipes.com/search?Pasta=Pasta&offset=84&q=Pasta&page=8\n",
      "Pasta https://www.allrecipes.com/search?Pasta=Pasta&offset=96&q=Pasta&page=9\n",
      "Pasta https://www.allrecipes.com/search?Pasta=Pasta&offset=108&q=Pasta&page=10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Dessert https://www.allrecipes.com/search?Dessert=Dessert&offset=0&q=Dessert&page=1\n",
      "Dessert https://www.allrecipes.com/search?Dessert=Dessert&offset=12&q=Dessert&page=2\n",
      "Dessert https://www.allrecipes.com/search?Dessert=Dessert&offset=24&q=Dessert&page=3\n",
      "Dessert https://www.allrecipes.com/search?Dessert=Dessert&offset=36&q=Dessert&page=4\n",
      "Dessert https://www.allrecipes.com/search?Dessert=Dessert&offset=48&q=Dessert&page=5\n",
      "Dessert https://www.allrecipes.com/search?Dessert=Dessert&offset=60&q=Dessert&page=6\n",
      "Dessert https://www.allrecipes.com/search?Dessert=Dessert&offset=72&q=Dessert&page=7\n",
      "Dessert https://www.allrecipes.com/search?Dessert=Dessert&offset=84&q=Dessert&page=8\n",
      "Dessert https://www.allrecipes.com/search?Dessert=Dessert&offset=96&q=Dessert&page=9\n",
      "Dessert https://www.allrecipes.com/search?Dessert=Dessert&offset=108&q=Dessert&page=10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Lasagna https://www.allrecipes.com/search?Lasagna=Lasagna&offset=0&q=Lasagna&page=1\n",
      "Lasagna https://www.allrecipes.com/search?Lasagna=Lasagna&offset=12&q=Lasagna&page=2\n",
      "Lasagna https://www.allrecipes.com/search?Lasagna=Lasagna&offset=24&q=Lasagna&page=3\n",
      "Lasagna https://www.allrecipes.com/search?Lasagna=Lasagna&offset=36&q=Lasagna&page=4\n",
      "Lasagna https://www.allrecipes.com/search?Lasagna=Lasagna&offset=48&q=Lasagna&page=5\n",
      "Lasagna https://www.allrecipes.com/search?Lasagna=Lasagna&offset=60&q=Lasagna&page=6\n",
      "Lasagna https://www.allrecipes.com/search?Lasagna=Lasagna&offset=72&q=Lasagna&page=7\n",
      "Lasagna https://www.allrecipes.com/search?Lasagna=Lasagna&offset=84&q=Lasagna&page=8\n",
      "Lasagna https://www.allrecipes.com/search?Lasagna=Lasagna&offset=96&q=Lasagna&page=9\n",
      "Lasagna https://www.allrecipes.com/search?Lasagna=Lasagna&offset=108&q=Lasagna&page=10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Pizza https://www.allrecipes.com/search?Pizza=Pizza&offset=0&q=Pizza&page=1\n",
      "Pizza https://www.allrecipes.com/search?Pizza=Pizza&offset=12&q=Pizza&page=2\n",
      "Pizza https://www.allrecipes.com/search?Pizza=Pizza&offset=24&q=Pizza&page=3\n",
      "Pizza https://www.allrecipes.com/search?Pizza=Pizza&offset=36&q=Pizza&page=4\n",
      "Pizza https://www.allrecipes.com/search?Pizza=Pizza&offset=48&q=Pizza&page=5\n",
      "Pizza https://www.allrecipes.com/search?Pizza=Pizza&offset=60&q=Pizza&page=6\n",
      "Pizza https://www.allrecipes.com/search?Pizza=Pizza&offset=72&q=Pizza&page=7\n",
      "Pizza https://www.allrecipes.com/search?Pizza=Pizza&offset=84&q=Pizza&page=8\n",
      "Pizza https://www.allrecipes.com/search?Pizza=Pizza&offset=96&q=Pizza&page=9\n",
      "Pizza https://www.allrecipes.com/search?Pizza=Pizza&offset=108&q=Pizza&page=10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Cookies https://www.allrecipes.com/search?Cookies=Cookies&offset=0&q=Cookies&page=1\n",
      "Cookies https://www.allrecipes.com/search?Cookies=Cookies&offset=12&q=Cookies&page=2\n",
      "Cookies https://www.allrecipes.com/search?Cookies=Cookies&offset=24&q=Cookies&page=3\n",
      "Cookies https://www.allrecipes.com/search?Cookies=Cookies&offset=36&q=Cookies&page=4\n",
      "Cookies https://www.allrecipes.com/search?Cookies=Cookies&offset=48&q=Cookies&page=5\n",
      "Cookies https://www.allrecipes.com/search?Cookies=Cookies&offset=60&q=Cookies&page=6\n",
      "Cookies https://www.allrecipes.com/search?Cookies=Cookies&offset=72&q=Cookies&page=7\n",
      "Cookies https://www.allrecipes.com/search?Cookies=Cookies&offset=84&q=Cookies&page=8\n",
      "Cookies https://www.allrecipes.com/search?Cookies=Cookies&offset=96&q=Cookies&page=9\n",
      "Cookies https://www.allrecipes.com/search?Cookies=Cookies&offset=108&q=Cookies&page=10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Vegetables https://www.allrecipes.com/search?Vegetables=Vegetables&offset=0&q=Vegetables&page=1\n",
      "Vegetables https://www.allrecipes.com/search?Vegetables=Vegetables&offset=12&q=Vegetables&page=2\n",
      "Vegetables https://www.allrecipes.com/search?Vegetables=Vegetables&offset=24&q=Vegetables&page=3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 124\u001b[0m\n\u001b[0;32m    120\u001b[0m                 total \u001b[38;5;241m=\u001b[39m scrap(dish, f, url, total)\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 124\u001b[0m     main(\u001b[38;5;241m10\u001b[39m)\n",
      "Cell \u001b[1;32mIn[11], line 120\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(page_count)\u001b[0m\n\u001b[0;32m    118\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.allrecipes.com/search?\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m+\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m20\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(dish\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m+\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m20\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(dish\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m&offset=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(i\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m12\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m&q=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m+\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m20\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(dish\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m&page=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28mprint\u001b[39m(dish, url)\n\u001b[1;32m--> 120\u001b[0m total \u001b[38;5;241m=\u001b[39m scrap(dish, f, url, total)\n",
      "Cell \u001b[1;32mIn[11], line 28\u001b[0m, in \u001b[0;36mscrap\u001b[1;34m(dish, f, url, total)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m#print(dish_url)\u001b[39;00m\n\u001b[0;32m     27\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[1;32m---> 28\u001b[0m page \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(dish_url, headers\u001b[38;5;241m=\u001b[39mheaders)\n\u001b[0;32m     29\u001b[0m page\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[0;32m     30\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"scrapping recipe website for ingredients\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    483\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    487\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    488\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    489\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[0;32m    490\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    491\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    492\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    493\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    494\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    495\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[0;32m    496\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    497\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    498\u001b[0m     )\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:714\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[0;32m    713\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 714\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    715\u001b[0m     conn,\n\u001b[0;32m    716\u001b[0m     method,\n\u001b[0;32m    717\u001b[0m     url,\n\u001b[0;32m    718\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    719\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    720\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    721\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    722\u001b[0m )\n\u001b[0;32m    724\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    725\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    726\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[0;32m    728\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:466\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    461\u001b[0m             httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    462\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    463\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    464\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    465\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m--> 466\u001b[0m             six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    467\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:461\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    459\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[0;32m    460\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 461\u001b[0m         httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    462\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    463\u001b[0m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    464\u001b[0m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    465\u001b[0m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m    466\u001b[0m         six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1373\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1374\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1375\u001b[0m         response\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[0;32m   1376\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1377\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_status()\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\ssl.py:1278\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1275\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1276\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1277\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nbytes, buffer)\n\u001b[0;32m   1279\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\ssl.py:1134\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1132\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1135\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"working code\"\"\"\n",
    "import urllib.request as urllib2\n",
    "import json\n",
    "import collections, itertools\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import requests\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "def scrap(dish, f, url, total):\n",
    "    try:\n",
    "        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'}\n",
    "        page = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        #print(soup)\n",
    "        \"\"\"accessing the recipe cards.\"\"\"\n",
    "        all_items = soup.find_all(\"a\", {'class': 'comp mntl-card-list-items mntl-document-card mntl-card card card--no-image'})\n",
    "        num=total\n",
    "        #print(all_items)\n",
    "        for item in all_items:\n",
    "            \"\"\"url of the recipe card/recipe website\"\"\"\n",
    "            dish_url = item['href']\n",
    "            image_url = item.find('img')['data-src']\n",
    "            #print(dish_url)\n",
    "            headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'}\n",
    "            page = requests.get(dish_url, headers=headers)\n",
    "            page.raise_for_status()\n",
    "            \"\"\"scrapping recipe website for ingredients\"\"\"\n",
    "            dish_folder = os.path.join(\"new_dataset\", dish)\n",
    "            l = len(os.listdir(dish_folder))+1\n",
    "            soup = BeautifulSoup(page.content, 'html.parser')\n",
    "            web_ingredients = soup.find_all(\"li\", {'class': 'mntl-structured-ingredients__list-item'})\n",
    "            ingredients = []\n",
    "            if web_ingredients and l<=50:\n",
    "                for ingredient_item in web_ingredients:\n",
    "                    quantity = ingredient_item.find(\"span\", {'data-ingredient-quantity': 'true'})\n",
    "                    unit = ingredient_item.find(\"span\", {'data-ingredient-unit': 'true'})\n",
    "                    name = ingredient_item.find(\"span\", {'data-ingredient-name': 'true'})\n",
    "\n",
    "                    formatted_ingredient = ''\n",
    "                    if quantity:\n",
    "                        formatted_ingredient += quantity.text.strip() + ' '\n",
    "                    if unit:\n",
    "                        formatted_ingredient += unit.text.strip() + ' '\n",
    "                    if name:\n",
    "                        formatted_ingredient += name.text.strip()\n",
    "                    ingredients.append(formatted_ingredient)\n",
    "                #print(ingredients)\n",
    "                \"\"\"scrapping recipe website for recipe steps\"\"\"\n",
    "                recipe_step_elements = soup.find_all('div', class_='comp recipe__steps mntl-block')\n",
    "                recipe_steps = []\n",
    "                for element in recipe_step_elements:\n",
    "                    p_elements = element.find_all('p',class_='comp mntl-sc-block mntl-sc-block-html')\n",
    "                    for p_element in p_elements:\n",
    "                        recipe_steps.append(p_element.get_text().strip())\n",
    "                #print(recipe_steps)\n",
    "                \"\"\"scrapping recipe website images\"\"\"\n",
    "                #print(image_url)\n",
    "                #print(dish)\n",
    "                save_image(dish, image_url)\n",
    "                result = str(dish) + \",\" + str(dish_url) + \",\" + str(ingredients) + \",\" + str(recipe_steps) + \"\\n\"\n",
    "                f.write(result)\n",
    "    except Exception as e:\n",
    "        print(f'Error while scraping: {e}')\n",
    "    finally:\n",
    "        pass\n",
    "\"\"\"def save_image(dish, image_url,num):\n",
    "    resp = requests.get(image_url, stream=True)\n",
    "    if not os.path.exists(\"dataset/\" + dish):\n",
    "        os.makedirs(\"dataset/\" + dish)\n",
    "    local_file = open(\"dataset/\" + dish + \"/\" + str(num) + \".jpg\", 'wb')\n",
    "    resp.raw.decode_content = True\n",
    "    shutil.copyfileobj(resp.raw, local_file)\n",
    "    del resp\n",
    "    return\"\"\"\n",
    "def save_image(dish, image_url):\n",
    "    try:\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'\n",
    "        }\n",
    "        resp = requests.get(image_url, stream=True, headers=headers)\n",
    "        if resp.status_code == 200:\n",
    "            # Ensure the \"dataset\" folder exists for each dish\n",
    "            dish_folder = os.path.join(\"new_dataset\", dish)\n",
    "            if not os.path.exists(dish_folder):\n",
    "                os.makedirs(dish_folder)\n",
    "\n",
    "            # Count the number of image files already saved for this dish\n",
    "            num = len(os.listdir(dish_folder))+1\n",
    "\n",
    "            # Save the image with a unique filename\n",
    "            image_filename = f\"{num}.jpg\"\n",
    "            image_path = os.path.join(dish_folder, image_filename)\n",
    "\n",
    "            with open(image_path, 'wb') as local_file:\n",
    "                resp.raw.decode_content = True\n",
    "                shutil.copyfileobj(resp.raw, local_file)\n",
    "        else:\n",
    "            print(f\"Error: Unable to download image for {dish}\")\n",
    "    except Exception as e:\n",
    "        print(f'Error saving image: {e}')\n",
    "\n",
    "# ... (rest of your code)\n",
    "\n",
    "def main(page_count):\n",
    "    file = open(\"new_classes.txt\", \"r\")\n",
    "    all_classes = file.read().split()\n",
    "    count = 0\n",
    "    with open('new_Recipes_capstone.txt', 'a', encoding='utf-8') as f:\n",
    "        for dish in all_classes:\n",
    "            total = 0\n",
    "            count += 1\n",
    "            print(\"\\n\\n\\n\\n\\n\" + str(count) + \"\\n\\n\\n\\n\")\n",
    "            for i in range(1, page_count + 1):\n",
    "                \"\"\"url = \"https://www.allrecipes.com/search?q=\" + '+'.join(dish.split('_')) + \"+recipe\" + \"&page=\" + str(i)\"\"\"\n",
    "                url = f\"https://www.allrecipes.com/search?{'+%20'.join(dish.split('_'))}={'+%20'.join(dish.split('_'))}&offset={(i - 1) * 12}&q={'+%20'.join(dish.split('_'))}&page={i}\"\n",
    "                print(dish, url)\n",
    "                total = scrap(dish, f, url, total)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942c9709",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Function to count the number of image files in a folder\n",
    "def count_images_in_folder(folder_path):\n",
    "    image_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.svg']  # Add more extensions as needed\n",
    "    image_count = 0\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if any(filename.lower().endswith(ext) for ext in image_extensions):\n",
    "            image_count += 1\n",
    "\n",
    "    return image_count\n",
    "\n",
    "# Read folder names from a file (one folder name per line)\n",
    "folder_names_file = \"new_classes.txt\"  # Replace with your file name\n",
    "with open(folder_names_file, \"r\") as file:\n",
    "    folder_names = file.read().splitlines()\n",
    "\n",
    "# Create a list of tuples containing folder names and their image counts\n",
    "folder_image_counts = []\n",
    "\n",
    "for folder_name in folder_names:\n",
    "    folder_path = os.path.join(\"new_dataset\", folder_name)  # Replace \"path_to_base_folder\" with the actual base folder path\n",
    "    image_count = count_images_in_folder(folder_path)\n",
    "    folder_image_counts.append((folder_name, image_count))\n",
    "\n",
    "# Sort the list based on image count in descending order\n",
    "folder_image_counts.sort(key=lambda x: x[1], reverse=True)\n",
    "folder_with=[]\n",
    "# Print folders with 50 images first and then the rest\n",
    "for folder_name, image_count in folder_image_counts:\n",
    "    if image_count == 50:\n",
    "        print(f\"Folder '{folder_name}' contains {image_count} image(s).\")\n",
    "        folder_with.append(folder_name)\n",
    "for folder_name, image_count in folder_image_counts:\n",
    "    if image_count != 50:\n",
    "        print(f\"Folder '{folder_name}' contains {image_count} image(s).\")\n",
    "print(folder_with)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
